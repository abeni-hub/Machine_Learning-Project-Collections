{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aUAtJzDI9fJP0xJFEVoiQ-KgxnncnFaE",
      "authorship_tag": "ABX9TyOJEJ2+PV4sBKbpGDlcR/9R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abeni-hub/Machine_Learning-Project-Collections/blob/main/Fruits_and_vegetable_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcb0dMPS8KqM",
        "outputId": "9f83a34b-0f20-43b4-e527-c579c05672b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ShLXnD8y_VI8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/train',\n",
        "    labels='inferred',\n",
        "    label_mode = \"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jDFLgMR_jF-",
        "outputId": "a04121cb-4741-42b6-e41c-de31ca4210b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1063 files belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation Testing"
      ],
      "metadata": {
        "id": "0Z_vAhPm8aW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/validation',\n",
        "    labels='inferred',\n",
        "    label_mode = \"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U786kGnHIwlv",
        "outputId": "2a20a1da-aed4-42b7-f0a5-b228edbb9310"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 351 files belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building MODEL"
      ],
      "metadata": {
        "id": "75p9_DPmLB7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = 64 , kernel_size = 3 , activation='relu',input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2 , strides = 2))"
      ],
      "metadata": {
        "id": "lY8nm-2qLEr7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 64 , kernel_size = 3 , activation='relu',input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2 , strides = 2))"
      ],
      "metadata": {
        "id": "C7_oNVrRM03H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5)) #Used to avoid overfitting"
      ],
      "metadata": {
        "id": "UprwuJS9M6B0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "TJSYDeOYNO0k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units =128 ,activation='relu')) # To make a neurons\n",
        "cnn.add(tf.keras.layers.Dense(units = 36 ,activation='softmax')) # To make output layers of the neuron"
      ],
      "metadata": {
        "id": "STFF9j4XNR8A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NoFlhkHhNj7M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compiling and Training Phase"
      ],
      "metadata": {
        "id": "UXEbLubwOXUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'rmsprop',loss ='categorical_crossentropy' , metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "f32hR_27Obgn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainign_history = cnn.fit(x = training_set , validation_data = validation_set , epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWEiU1AAO55s",
        "outputId": "8906047a-de68-448d-e8f6-7a49cee39a74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "34/34 [==============================] - 324s 8s/step - loss: 14.7337 - accuracy: 0.1054 - val_loss: 5.1674 - val_accuracy: 0.0285\n",
            "Epoch 2/30\n",
            "34/34 [==============================] - 43s 1s/step - loss: 4.4295 - accuracy: 0.1759 - val_loss: 4.9552 - val_accuracy: 0.1111\n",
            "Epoch 3/30\n",
            "34/34 [==============================] - 39s 1s/step - loss: 3.0025 - accuracy: 0.2653 - val_loss: 7.9350 - val_accuracy: 0.1538\n",
            "Epoch 4/30\n",
            "34/34 [==============================] - 37s 985ms/step - loss: 3.1506 - accuracy: 0.3151 - val_loss: 27.2088 - val_accuracy: 0.0627\n",
            "Epoch 5/30\n",
            "34/34 [==============================] - 38s 979ms/step - loss: 3.3161 - accuracy: 0.3575 - val_loss: 28.2938 - val_accuracy: 0.0826\n",
            "Epoch 6/30\n",
            "34/34 [==============================] - 43s 1s/step - loss: 2.9435 - accuracy: 0.4741 - val_loss: 19.2886 - val_accuracy: 0.2137\n",
            "Epoch 7/30\n",
            "34/34 [==============================] - 37s 987ms/step - loss: 4.0498 - accuracy: 0.5334 - val_loss: 42.4078 - val_accuracy: 0.1738\n",
            "Epoch 8/30\n",
            "34/34 [==============================] - 38s 979ms/step - loss: 1.2095 - accuracy: 0.6858 - val_loss: 19.4612 - val_accuracy: 0.2991\n",
            "Epoch 9/30\n",
            "34/34 [==============================] - 47s 1s/step - loss: 1.3875 - accuracy: 0.6811 - val_loss: 37.9622 - val_accuracy: 0.2650\n",
            "Epoch 10/30\n",
            "34/34 [==============================] - 39s 1s/step - loss: 1.6680 - accuracy: 0.7253 - val_loss: 26.7584 - val_accuracy: 0.2963\n",
            "Epoch 11/30\n",
            "34/34 [==============================] - 45s 1s/step - loss: 1.0080 - accuracy: 0.7611 - val_loss: 63.1753 - val_accuracy: 0.2593\n",
            "Epoch 12/30\n",
            "34/34 [==============================] - 37s 985ms/step - loss: 2.1747 - accuracy: 0.7611 - val_loss: 64.1022 - val_accuracy: 0.1282\n",
            "Epoch 13/30\n",
            "34/34 [==============================] - 47s 1s/step - loss: 1.3609 - accuracy: 0.8043 - val_loss: 38.5243 - val_accuracy: 0.3305\n",
            "Epoch 14/30\n",
            "34/34 [==============================] - 37s 980ms/step - loss: 0.5868 - accuracy: 0.8627 - val_loss: 39.2522 - val_accuracy: 0.2934\n",
            "Epoch 15/30\n",
            "34/34 [==============================] - 38s 976ms/step - loss: 0.6216 - accuracy: 0.8655 - val_loss: 37.1517 - val_accuracy: 0.3419\n",
            "Epoch 16/30\n",
            "34/34 [==============================] - 48s 1s/step - loss: 0.7158 - accuracy: 0.8570 - val_loss: 46.0028 - val_accuracy: 0.3305\n",
            "Epoch 17/30\n",
            "34/34 [==============================] - 37s 985ms/step - loss: 0.6077 - accuracy: 0.8796 - val_loss: 40.7754 - val_accuracy: 0.3305\n",
            "Epoch 18/30\n",
            "34/34 [==============================] - 37s 992ms/step - loss: 1.2923 - accuracy: 0.8495 - val_loss: 33.6826 - val_accuracy: 0.3419\n",
            "Epoch 19/30\n",
            "34/34 [==============================] - 38s 977ms/step - loss: 0.2851 - accuracy: 0.9313 - val_loss: 39.1509 - val_accuracy: 0.3362\n",
            "Epoch 20/30\n",
            "34/34 [==============================] - 48s 1s/step - loss: 1.3744 - accuracy: 0.8617 - val_loss: 61.7241 - val_accuracy: 0.2963\n",
            "Epoch 21/30\n",
            "34/34 [==============================] - 38s 1s/step - loss: 0.6336 - accuracy: 0.8871 - val_loss: 54.6601 - val_accuracy: 0.3333\n",
            "Epoch 22/30\n",
            "34/34 [==============================] - 37s 1s/step - loss: 1.1893 - accuracy: 0.8899 - val_loss: 42.1199 - val_accuracy: 0.3419\n",
            "Epoch 23/30\n",
            "34/34 [==============================] - 39s 989ms/step - loss: 0.4223 - accuracy: 0.9351 - val_loss: 56.1156 - val_accuracy: 0.3219\n",
            "Epoch 24/30\n",
            "34/34 [==============================] - 47s 1s/step - loss: 1.0999 - accuracy: 0.8956 - val_loss: 55.4800 - val_accuracy: 0.3333\n",
            "Epoch 25/30\n",
            "34/34 [==============================] - 43s 1s/step - loss: 0.3641 - accuracy: 0.9389 - val_loss: 55.4495 - val_accuracy: 0.3305\n",
            "Epoch 26/30\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.4974 - accuracy: 0.9304 - val_loss: 60.0866 - val_accuracy: 0.3333\n",
            "Epoch 27/30\n",
            "34/34 [==============================] - 37s 986ms/step - loss: 0.5256 - accuracy: 0.9304 - val_loss: 73.4966 - val_accuracy: 0.3276\n",
            "Epoch 28/30\n",
            "34/34 [==============================] - 37s 988ms/step - loss: 0.4302 - accuracy: 0.9398 - val_loss: 85.7371 - val_accuracy: 0.3362\n",
            "Epoch 29/30\n",
            "34/34 [==============================] - 42s 1s/step - loss: 0.4474 - accuracy: 0.9426 - val_loss: 74.1510 - val_accuracy: 0.3305\n",
            "Epoch 30/30\n",
            "34/34 [==============================] - 38s 993ms/step - loss: 0.4022 - accuracy: 0.9492 - val_loss: 71.9320 - val_accuracy: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving Model"
      ],
      "metadata": {
        "id": "GFoNiCyjP6Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save"
      ],
      "metadata": {
        "id": "Zp_1KoE6PpTW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fdb6e3e9-adfe-47f2-c880-b2e5506f2759"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.save of <keras.src.engine.sequential.Sequential object at 0x7eb955c9f610>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.engine.training.Model.save</b><br/>def save(filepath, overwrite=True, save_format=None, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py</a>Saves a model as a TensorFlow SavedModel or HDF5 file.\n",
              "\n",
              "See the [Serialization and Saving guide](\n",
              "    https://keras.io/guides/serialization_and_saving/) for details.\n",
              "\n",
              "Args:\n",
              "    model: Keras model instance to be saved.\n",
              "    filepath: `str` or `pathlib.Path` object. Path where to save the\n",
              "        model.\n",
              "    overwrite: Whether we should overwrite any existing model at the\n",
              "        target location, or instead ask the user via an interactive\n",
              "        prompt.\n",
              "    save_format: Either `&quot;keras&quot;`, `&quot;tf&quot;`, `&quot;h5&quot;`,\n",
              "        indicating whether to save the model\n",
              "        in the native Keras format (`.keras`),\n",
              "        in the TensorFlow SavedModel format\n",
              "        (referred to as &quot;SavedModel&quot; below),\n",
              "        or in the legacy HDF5 format (`.h5`).\n",
              "        Defaults to `&quot;tf&quot;` in TF 2.X, and `&quot;h5&quot;` in TF 1.X.\n",
              "\n",
              "SavedModel format arguments:\n",
              "    include_optimizer: Only applied to SavedModel and legacy HDF5\n",
              "        formats. If False, do not save the optimizer state.\n",
              "        Defaults to `True`.\n",
              "    signatures: Only applies to SavedModel format. Signatures to save\n",
              "        with the SavedModel. See the `signatures` argument in\n",
              "        `tf.saved_model.save` for details.\n",
              "    options: Only applies to SavedModel format.\n",
              "        `tf.saved_model.SaveOptions` object that specifies SavedModel\n",
              "        saving options.\n",
              "    save_traces: Only applies to SavedModel format. When enabled, the\n",
              "        SavedModel will store the function traces for each layer. This\n",
              "        can be disabled, so that only the configs of each layer are\n",
              "        stored. Defaults to `True`.\n",
              "        Disabling this will decrease serialization time\n",
              "        and reduce file size, but it requires that all custom\n",
              "        layers/models implement a `get_config()` method.\n",
              "\n",
              "Example:\n",
              "\n",
              "```python\n",
              "model = tf.keras.Sequential([\n",
              "    tf.keras.layers.Dense(5, input_shape=(3,)),\n",
              "    tf.keras.layers.Softmax()])\n",
              "model.save(&quot;model.keras&quot;)\n",
              "loaded_model = tf.keras.models.load_model(&quot;model.keras&quot;)\n",
              "x = tf.random.uniform((10, 3))\n",
              "assert np.allclose(model.predict(x), loaded_model.predict(x))\n",
              "```\n",
              "\n",
              "Note that `model.save()` is an alias for `tf.keras.models.save_model()`.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 3049);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}