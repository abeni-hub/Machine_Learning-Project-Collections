{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abeni-hub/Machine_Learning-Project-Collections/blob/main/Copy_of_fcc_sms_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"train-data.tsv\",sep='\\t', header= None)\n",
        "df.columns =['label', 'message']\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('label').describe().T"
      ],
      "metadata": {
        "id": "1U09erhjFnkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get all the ham and spam emails\n",
        "ham_msg = df[df.label =='ham']\n",
        "spam_msg = df[df.label=='spam']# Create numpy list to visualize using wordcloud\n",
        "ham_msg_text = \" \".join(ham_msg.message.to_numpy().tolist())\n",
        "spam_msg_text = \" \".join(spam_msg.message.to_numpy().tolist())"
      ],
      "metadata": {
        "id": "CJScThhbF4c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "ham_msg_cloud = WordCloud(width =320, height =160, stopwords=STOPWORDS,max_font_size=50, background_color =\"black\", colormap='Blues').generate(ham_msg_text)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(ham_msg_cloud, interpolation='bilinear')\n",
        "plt.axis('off') # turn off axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8p2nNvDDF-G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "ham_msg_cloud = WordCloud(width =320, height =160, stopwords=STOPWORDS,max_font_size=50, background_color =\"white\", colormap='autumn').generate(spam_msg_text)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(ham_msg_cloud, interpolation='bilinear')\n",
        "plt.axis('off') # turn off axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gWvCpjvYGHyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.countplot(df.label)\n",
        "# Percentage of spam messages\n",
        "(len(spam_msg)/len(ham_msg))*100 # 15.48%"
      ],
      "metadata": {
        "id": "hFUrUb31GPJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one way to fix it is to downsample the ham msg\n",
        "ham_msg_df = ham_msg.sample(n = len(spam_msg), random_state = 0)\n",
        "spam_msg_df = spam_msg\n",
        "print(ham_msg_df.shape, spam_msg_df.shape)#(747, 2) (747, 2)"
      ],
      "metadata": {
        "id": "sIxn0QMVGTWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pandas.concat instead of append\n",
        "msg_df = pd.concat([ham_msg_df, spam_msg_df]).reset_index(drop=True)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.countplot(msg_df.label)\n",
        "plt.title('Distribution of ham and spam email messages (after downsampling)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QR5sLzh_GXk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get length column for each text\n",
        "msg_df['text_length'] = msg_df['message'].apply(len) #Calculate average length by label types\n",
        "labels = msg_df.groupby('label')['text_length'].mean() # Calculate mean of the 'text_length' column\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "LHnFLLeVGwFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"valid-data.tsv\",sep='\\t', header= None)\n",
        "df_test.columns =['label', 'message']\n",
        "df_test.tail()"
      ],
      "metadata": {
        "id": "nunzsMHyG-GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg_df['msg_type']= msg_df['label'].map({'ham': 0, 'spam': 1})\n",
        "df_test['msg_type']= df_test['label'].map({'ham': 0, 'spam': 1})\n",
        "print(msg_df.tail())\n",
        "print(df_test.tail())\n"
      ],
      "metadata": {
        "id": "AC8C1os4HL4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = msg_df['msg_type']\n",
        "train_msg = msg_df['message']\n",
        "test_msg = df_test['message']\n",
        "test_label = df_test['msg_type']\n",
        "print(test_msg)\n",
        "print(train_msg)\n"
      ],
      "metadata": {
        "id": "Em30GXE0HQtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Defining pre-processing hyperparameters\n",
        "max_len = 50\n",
        "trunc_type = \"post\"\n",
        "padding_type = \"post\"\n",
        "oov_tok = \"\"\n",
        "vocab_size = 500\n"
      ],
      "metadata": {
        "id": "KnOw9Q2qHV7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9npVPRglHadd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# ... rest of your code\n",
        "tokenizer = Tokenizer(num_words = vocab_size, char_level=False, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(train_msg)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pm0DNczVHjjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "tot_words = len(word_index)\n",
        "print('There are %s unique tokens in training data. ' % tot_words)"
      ],
      "metadata": {
        "id": "5L-XM3zaHtAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(train_msg)\n",
        "training_padded = pad_sequences (training_sequences, maxlen = max_len, padding = padding_type, truncating = trunc_type )\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_msg)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen = max_len,padding = padding_type, truncating = trunc_type)\n"
      ],
      "metadata": {
        "id": "J5b4TPUgHwfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training tensor: ', training_padded.shape)\n",
        "print('Shape of testing tensor: ', testing_padded.shape)\n"
      ],
      "metadata": {
        "id": "WkdCyfdaH2B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_padded[0])"
      ],
      "metadata": {
        "id": "g8wXdABKH3HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab_size = 500 # As defined earlier\n",
        "embeding_dim = 16\n",
        "drop_value = 0.2 # dropout\n",
        "n_dense = 24"
      ],
      "metadata": {
        "id": "JdcNi0QQI_7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout, LSTM, Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embeding_dim, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dropout(drop_value))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "KONjyzwgJD0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "DLEIbfBgJj5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "__q_8XFQKUiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(training_padded, train_label, epochs=num_epochs, validation_data=(testing_padded, test_label),callbacks =[early_stop], verbose=2)\n"
      ],
      "metadata": {
        "id": "aGTSnqSGKdH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testing_padded, test_label)"
      ],
      "metadata": {
        "id": "UYrh2_iyKo1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting a dense spam detector model\n",
        "num_epochs = 30\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(training_padded, train_label, epochs=num_epochs, validation_data=(testing_padded, test_label),callbacks =[early_stop], verbose=2)"
      ],
      "metadata": {
        "id": "R0y4rHM7UDdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testing_padded, test_label)"
      ],
      "metadata": {
        "id": "YdRBh63PW_6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "# Rename column\n",
        "metrics.rename(columns = {'loss': 'Training_Loss', 'accuracy': 'Training_Accuracy', 'val_loss': 'Validation_Loss', 'val_accuracy': 'Validation_Accuracy'}, inplace = True)\n",
        "def plot_graphs1(var1, var2, string):\n",
        "    metrics[[var1, var2]].plot()\n",
        "    plt.title('Training and Validation ' + string)\n",
        "    plt.xlabel ('Number of epochs')\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([var1, var2])"
      ],
      "metadata": {
        "id": "fACnI4dQXK0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plot_graphs1('Training_Accuracy', 'Validation_Accuracy', 'accuracy')"
      ],
      "metadata": {
        "id": "PwjLJfq1XUIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text1):\n",
        "  pred_text = []\n",
        "  pred_text.append(pred_text1)\n",
        "  new_seq = tokenizer.texts_to_sequences(pred_text)\n",
        "  padded = pad_sequences(new_seq, maxlen =max_len,padding = padding_type,truncating=trunc_type)\n",
        "  prediction = model.predict(padded)\n",
        "  for i in prediction:\n",
        "    if i > 0.5:\n",
        "      return((float(i),\"spam\"))\n",
        "    else:\n",
        "      return((float(i),\"ham\"))\n",
        "\n",
        "pred_text = \" you have won £1000 cash! call to claim\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}